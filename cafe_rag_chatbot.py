# cafe_rag_chatbot.py

import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- ë°ì´í„° ë° ì„¤ì • ---
from cafe_menu_data import CAFE_DATA

DB_PATH = "vector_db"
DB_FAISS_PATH = os.path.join(DB_PATH, "faiss_index")

class CafeRAGChatbot:
    """ì¹´í˜ í‚¤ì˜¤ìŠ¤í¬ RAG ì±—ë´‡ ì‹œìŠ¤í…œ (ìš´ì˜ìš©)"""

    def __init__(self):
        """ì´ˆê¸°í™” ì‹œ, ë¯¸ë¦¬ êµ¬ì¶•ëœ ë²¡í„° DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)
        self.embeddings = OpenAIEmbeddings()
        
        # 1. ì›ë³¸ ë©”ë‰´ ë°ì´í„° ë¡œë“œ
        self.menus = CAFE_DATA.get('menus', [])
        
        # 2. ë¯¸ë¦¬ ë§Œë“¤ì–´ì§„ FAISS ë²¡í„° DB ë¡œë“œ
        if not os.path.exists(DB_FAISS_PATH):
            raise FileNotFoundError(f"ë²¡í„° DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € build_vector_db.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”. ê²½ë¡œ: {DB_FAISS_PATH}")
        
        print(f"ğŸ“‚ ë¡œì»¬ ë²¡í„° DB ë¡œë“œ ì¤‘: {DB_FAISS_PATH}")
        self.vectorstore = FAISS.load_local(
            folder_path=DB_FAISS_PATH,
            embeddings=self.embeddings,
            allow_dangerous_deserialization=True
        )
        print("âœ… ë²¡í„° DB ë¡œë“œ ì™„ë£Œ!")
        
        # [ìµœì í™”] ë™ì˜ì–´ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ„í•´ menu_id-Document ë§µ ë¯¸ë¦¬ ìƒì„±
        self.doc_map = {doc.metadata['menu_id']: doc for doc in self.vectorstore.docstore._dict.values()}

        # 3. RAG Chain ìƒì„±
        self.rag_chain = self._create_rag_chain()
        
        print(f"ğŸ¤– ì¹´í˜ RAG ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ({len(self.menus)}ê°œ ë©”ë‰´)")

    def _search(self, query: str, k: int = 5) -> list[tuple[Document, float]]:
        """ë™ì˜ì–´ ì§ì ‘ ë§¤ì¹­ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        query_lower = query.lower()
        
        # 1. ë™ì˜ì–´ ì§ì ‘ ë§¤ì¹­ (ë” íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ ê°œì„ )
        for menu in self.menus:
            if any(synonym.lower() in query_lower for synonym in menu['synonyms']):
                matched_doc = self.doc_map.get(menu['menu_id'])
                if matched_doc:
                    print(f"ğŸ¯ ë™ì˜ì–´ ì§ì ‘ ë§¤ì¹­: '{query}' -> '{menu['name']}'")
                    # ì§ì ‘ ë§¤ì¹­ ì‹œ ë§¤ìš° ë†’ì€ ì ìˆ˜ ë¶€ì—¬
                    return [(matched_doc, 100.0 * matched_doc.metadata.get('search_boost_score', 1.0))]

        # 2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
        print(f"ğŸ” ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰: '{query}'")
        results = self.vectorstore.similarity_search_with_score(query, k=k)
        
        # 3. Boost ì ìˆ˜ ê°€ì¤‘ì¹˜ ì ìš©
        weighted = [
            (doc, (1 / (1 + score)) * doc.metadata.get('search_boost_score', 1.0))
            for doc, score in results
        ]
        weighted.sort(key=lambda x: x[1], reverse=True)
        return weighted

    def _format_context(self, results: list[tuple[Document, float]], max_results: int = 3) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•  Context ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not results:
            return "ê´€ë ¨ ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        parts = []
        for i, (doc, score) in enumerate(results[:max_results], 1):
            meta = doc.metadata
            size_prices = meta.get('size_prices', {})
            calories = meta.get('calories', {})
            allergens = meta.get('allergens', [])
            promotion = meta.get('promotion')

            info = f"""
[ë©”ë‰´ {i}] {meta.get('name', 'N/A')} (ê²€ìƒ‰ ì ìˆ˜: {score:.2f})
- ê°€ê²©: Regular {meta.get('base_price', 'N/A')}ì›, Large {size_prices.get('Large', 'N/A')}ì›
- ì¹¼ë¡œë¦¬: {calories.get('regular', 'N/A')}kcal (Regular ê¸°ì¤€)
- ì•ŒëŸ¬ì§€: {', '.join(allergens) if allergens else 'ì—†ìŒ'}"""
            
            if promotion:
                info += f"\n- í”„ë¡œëª¨ì…˜: {promotion.get('description', 'ë‚´ìš© ì—†ìŒ')}"
            parts.append(info.strip())
            
        return "\n\n---\n\n".join(parts)

    def _create_rag_chain(self):
        """LangChain Expression Language (LCEL)ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG Chain ìƒì„±"""
        system_prompt = """
ë‹¹ì‹ ì€ ìŠ¤ë§ˆíŠ¸ ì¹´í˜ì˜ ì „ë¬¸ ë°”ë¦¬ìŠ¤íƒ€ AIì…ë‹ˆë‹¤. ê³ ê°ì˜ ì§ˆë¬¸ì— ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

**ê·œì¹™**:
1. ì œê³µëœ [ê²€ìƒ‰ëœ ë©”ë‰´ ì •ë³´]ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ë¡œ ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
2. ê°€ê²©, ì¹¼ë¡œë¦¬ ì •ë³´ëŠ” ë°˜ë“œì‹œ "Regular ì‚¬ì´ì¦ˆ ê¸°ì¤€"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
3. ê³ ê°ì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬, ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë©”ë‰´ 1~2ê°œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
4. ë‹µë³€ì€ í•­ìƒ ë¶€ë“œëŸ½ê³  ì¹œì ˆí•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë©°, 2-3 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•µì‹¬ë§Œ ì „ë‹¬í•˜ì„¸ìš”.
5. í”„ë¡œëª¨ì…˜ ì •ë³´ê°€ ìˆë‹¤ë©´, ë†“ì¹˜ì§€ ë§ê³  ê¼­ ì•ˆë‚´í•˜ì—¬ ê³ ê°ì—ê²Œ í˜œíƒì„ ì£¼ì„¸ìš”.
6. ê´€ë ¨ëœ ë©”ë‰´ë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ë©´, "ì£„ì†¡í•˜ì§€ë§Œ ë¬¸ì˜í•˜ì‹  ë‚´ìš©ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë©”ë‰´ë¥¼ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ë¬¸ì„ ë„ì™€ë“œë¦´ê¹Œìš”?" ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.

[ê²€ìƒ‰ëœ ë©”ë‰´ ì •ë³´]
{context}

[ê³ ê° ì§ˆë¬¸]
{question}

[AI ë°”ë¦¬ìŠ¤íƒ€ ë‹µë³€]
"""
        prompt = ChatPromptTemplate.from_messages([("system", system_prompt)])
        
        return (
            {
                "context": lambda x: self._format_context(self._search(x['question'])),
                "question": lambda x: x['question']
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

    def ask(self, query: str) -> str:
        """ì±—ë´‡ì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤."""
        return self.rag_chain.invoke({"question": query})

if __name__ == "__main__":
    try:
        cafe_bot = CafeRAGChatbot()
        
        print("\n" + "="*60)
        print("â˜•ï¸ğŸ° ìŠ¤ë§ˆíŠ¸ ì¹´í˜ AI ë°”ë¦¬ìŠ¤íƒ€ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
        print("="*60)
        print("ğŸ’¡ ë©”ë‰´, ê°€ê²©, ì¶”ì²œ ë“± ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")
        print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ', 'exit', 'quit' ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("="*60 + "\n")
        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
                user_input = input("ğŸ‘¤ ì§ˆë¬¸: ").strip()
                
                # ì¢…ë£Œ ëª…ë ¹ì–´ ì²´í¬
                if user_input.lower() in ['ì¢…ë£Œ', 'exit', 'quit', 'ë‚˜ê°€ê¸°', 'ê·¸ë§Œ']:
                    print("\nğŸ‘©ğŸ»â€ğŸ³ ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜•\n")
                    break
                
                # ë¹ˆ ì…ë ¥ ì²´í¬
                if not user_input:
                    print("ğŸ‘©ğŸ»â€ğŸ³ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
                    continue
                
                # ì±—ë´‡ ì‘ë‹µ ìƒì„±
                print("\nğŸ‘©ğŸ»â€ğŸ³ ë‹µë³€: ", end="")
                response = cafe_bot.ask(user_input)
                print(response)
                print("\n" + "-"*60 + "\n")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘©ğŸ»â€ğŸ³ ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜•\n")
                break
            except Exception as e:
                print(f"\nâš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\n")
                continue

    except FileNotFoundError as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ ë¨¼ì € 'python build_vector_db.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë²¡í„° DBë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n")
    except Exception as e:
        print(f"\nâŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\n")